## 1 前言
人工智能的热潮已经到来，推动这一热潮的主力毫无疑问是深度学习。在深度学习诞生后的十年内，过去无法在计算机领域完成的任务，也渐渐被纳入可计算范围。一些曾被看作“科幻”的项目，比如智能对话，自动驾驶等，也一步步走向现实。</p>
随着其复杂程度不断·增加，研发一个和深度学习相关的项目，其规模比传统算法的开发要大得多。本文将从对于软件工程师的角度介绍如何从零开始完成深度学习技术的项目。</p>

## 2 智能 = 数据 + 标签？
深度学习有着极其出色的工作能力，但若想达到“智能”的境界，需要充分的训练数据。人类擅长从事物发展中总结规律，可以轻松地「举一反三」。但遗憾的是，深度学习模型并不具有这样的能力。对它来说，数据越充分越好。</p>
我们该如何解决这样的问题呢？</p>
以「虚拟背景」这一项目为例。虚拟背景的本质是图像分割，既模型输出一张 mask，属于人像的像素是白色，属于背景的像素是黑色。在此，如何建立训练数据集是非常重要的一环。
粗略地说，方法一共有两种。</p>
针对我们的使用场景，我们可以收集图像，并逐一为其制作标签。</p>
【图】</p>
不过，这样精细的标注，标注五六千张或许尚可接受，若达到一万，两万张，就有些吃力了。
于是人们寻求更为高效的办法：用「教师模型」辅助生成标注，在此基础上人工参与纠正错误。这一方法可以大大节省人力。</p>
然而无论是这两种方法的哪一种，都需要收集足够数量的图片。如此一来，收集数十万，数百万的图片就想当费力了。</p>
【图， augmentation】</p>
可通过 image augmentation 技术将图像数量翻倍扩张。实际上，这样的技巧并不限于翻转，缩放等简单的图像变换。只要变换后的图像仍然符合实际使用场景的分布，就可以加入训练数据集，以缓解数据不足的问题。

## 3 脑容量 = 结构 + 参数量？
在深度学习诞生后的十五年内，其模型复杂程度不断增加。我们可以理解其中的一些结构，但无法解释这些结构组合起来如何发挥出如此强大的能力。</p>
所以人们使用「炼丹」形容深度学习。尤其是，從AlphaGo開始，就有很多人提到過AI的思考過程其實是一個「黑箱」，我們很難確定AI到底是怎麼具體「思考」的。</p>
诸如「模型的深度增加仍然不会梯度爆炸/消失」的技巧在深度学习领域不胜枚举。但这些不是本文讨论的重点。因为顶尖的算法科学家们研究设计了许多表现优异的模型结构，发表了许多类似 Transformer、EfficientNet 这些具有划时代意义的论文。对于算法工程师来说，研究在任务的领域的最新进展，可以获得“什么模型可以拿来试试，什么模型不合适”的知识结构。</p>
深度学习网络的学习能力过于强大，以至于我们在训练模型时最担心遇到、但也是最常见的问题————过拟合。</p>
过拟合的含义是模型在训练集的表现过于好了，但在验证集的表现却不尽人意。</p>
那么如何防止过拟合呢？</p>
简单来说，就是让模型从全盘记忆转换成记忆「模式」就好了。即让模型拟合数据集的分布，学习本质的特征。</p>
此时需要再次强调前文所说的数据集的重要性。有时模型的表现不尽人意，多半是数据集的错误引起的。一个模型只可能和数据集一样优秀。在模型训练初期，我的时间大部分花在浏览每一张数据和标签。我会发现一些重复的数据，和不准确的标注。除此以外，也要小心使用“数据增强”这一魔法，因为不恰当的增强方式反而会引入噪声，从而让模型更难学习到数据集本质的特征。

## 4 性能优化
在得到一个满意的模型后，对于软件开发者的征程才刚刚开始。若想将深度学习的 feature 落地，需要面临的挑战是兼容多种多样的平台、硬件、系统版本。以及运行庞大的模型，更要兼顾模型准确度和算力。模型越轻量就越高效，代价是牺牲一部分准确度和可靠性；然而复杂大模型在保证准确的同时会消耗更多的计算资源。</p>
在此介绍一个概念，（Floating Point Operations Per Second）FLOPS，中文是「每秒钟的浮点运算数量」。对于深度学习模型来说，意味着在进行一次前向传播时需要执行的浮点运算次数，通常用于衡量模型的计算复杂度和优化模型的设计。通常来说，模型的   FLOPS 越大，意味着需要的计算资源越多，推理一次也需要更长时间。而性能调优的目标也是在降低 FLOPS 的同时最大化模型的准确度。 </p>
本文将介绍几个简单的性能调优办法。</p>
### 4.1 模型轻量化
- 模型剪枝 </p>
最直接的方法是减少模型参数，把模型中权重较小的层扔掉。这一过程可以类比 dropout。</p>
- 模型量化 </p>
- 知识蒸馏 </p>
### 4.2 在设备上优化
- 静态/动态性能控制 </p>

- 利用 GPU/NPU/..PU 加速
- 优化算子

## 5 模型迭代 = 唯有源头活水来
在把模型部署到产品中并投入产线后，我们该如何迭代更新，维护并提高 feature 的质量？</p>

毋庸置疑，模型在实际场景中会犯错误。越多人使用，越可能触发给出错误答案的情况，收集到的问题数据就越多。人类在模型的成长过程中承担着教师的角色 —— 收集数据并重新标注。训练数据集加入新数据后，损失函数会随之增大，模型不再忽视那些错误，而是从人为纠正过的标注进行学习。按照此方法微调后，准确度会有所上升。</p>
为保证每次迭代不至于引入 regression 问题，我们会使用 A/B 测试来比较质量和性能，进而决定是否更新模型。</p>


## 结语
正如阅读本文的各位或许听说过「涌现」这一词汇。「涌现」是一个专业概念，放在大模型的语境里，指的是模型在突破某个规模时，出现了意想不到的能力。虽然我们一直在讨论 AI 是否能产生真正的智慧。但人类对于何为真正的智慧并没有那么清楚。对于开发者来说，结合前沿技术研发新 feature 还是为了提升用户体验。比如 speech-to-text 技术，可以有效帮助听力障碍人士。或许設計人工智能的價值應該在這裏：通過人為設計，人工智能可以激起人類很豐富的體驗。當然這不是一項簡單的工作，有助模型质量提升的数据是在人工智能和人的互動中获得的。开发者需要依賴用戶的反饋，才能分析和學習原有的不足，改進我的設計。這種循環中，人工智能需要人類陪伴才能成長，我們需要對它投入精力地付出和教育。</p>
